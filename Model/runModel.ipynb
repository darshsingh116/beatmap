{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataReadFromDisk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from: E:\\\\Notebooks\\\\osu\\processed-metadata\\processed-metadata.csv\n"
     ]
    }
   ],
   "source": [
    "df = load_df_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "PARSING ERROR SOMEWHERE : Beatmap timestamp 10081.0ms is smaller than previous which is10360.0 10000.0 9640.0in map 6fc07475587f45a69547eb7f9b51a0c3/0013ddfd8bd55fdccc0b253e313b7a60.osu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m process_audio_and_beatmap_for_model_all_and_save(df)\n",
      "File \u001b[1;32me:\\Notebooks\\osu\\Model\\dataReadFromDisk.py:190\u001b[0m, in \u001b[0;36mprocess_audio_and_beatmap_for_model_all_and_save\u001b[1;34m(df, chunk_size)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Iterate through the DataFrame\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m--> 190\u001b[0m     processed_audio, processed_beatmap \u001b[38;5;241m=\u001b[39m process_audio_and_beatmap_for_model_single(row)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# Append the processed data to lists\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     processed_audio_list\u001b[38;5;241m.\u001b[39mappend(processed_audio)\n",
      "File \u001b[1;32me:\\Notebooks\\osu\\Model\\dataReadFromDisk.py:135\u001b[0m, in \u001b[0;36mprocess_audio_and_beatmap_for_model_single\u001b[1;34m(metadata)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beatmap_itr \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m beatmap_data[beatmap_itr][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m<\u001b[39m beatmap_data[beatmap_itr\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPARSING ERROR SOMEWHERE : Beatmap timestamp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeatmap_data[beatmap_itr][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mms is smaller than previous which is\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeatmap_data[beatmap_itr\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeatmap_data[beatmap_itr\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeatmap_data[beatmap_itr\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124min map \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfolder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.osu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Calculate the timestamp for this chunk in ms\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(processed_beatmap) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: PARSING ERROR SOMEWHERE : Beatmap timestamp 10081.0ms is smaller than previous which is10360.0 10000.0 9640.0in map 6fc07475587f45a69547eb7f9b51a0c3/0013ddfd8bd55fdccc0b253e313b7a60.osu"
     ]
    }
   ],
   "source": [
    "process_audio_and_beatmap_for_model_all_and_save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed\n",
    "\n",
    "# Define the model\n",
    "def create_lstm_model(input_shape, output_units):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layer\n",
    "    model.add(LSTM(units=128, return_sequences=True, input_shape=input_shape))\n",
    "    \n",
    "    # TimeDistributed layer with Dense to apply Dense to each time step\n",
    "    model.add(TimeDistributed(Dense(units=output_units, activation='softmax')))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Assuming the input and output arrays are stored in .npy files\n",
    "# Example function to load data\n",
    "def load_data(input_files, output_files):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for input_file, output_file in zip(input_files, output_files):\n",
    "        X.append(np.load(input_file))\n",
    "        Y.append(np.load(output_file))\n",
    "    \n",
    "    X = np.concatenate(X, axis=0)  # Concatenate all chunks into one large array\n",
    "    Y = np.concatenate(Y, axis=0)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "# Example file lists\n",
    "input_files = [\"input_chunk1.npy\"]\n",
    "output_files = [\"output_chunk1.npy\"]\n",
    "\n",
    "# # Load the data\n",
    "# X, Y = load_data(input_files, output_files)\n",
    "\n",
    "# # Define input shape (timesteps, features) and number of output units\n",
    "# input_shape = (X.shape[1], X.shape[2])  # (timesteps, features)\n",
    "# output_units = Y.shape[2]  # Number of features in the output sequence\n",
    "\n",
    "# # Create the model\n",
    "# model = create_lstm_model(input_shape, output_units)\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X, Y, batch_size=32, epochs=20)\n",
    "\n",
    "# # Save the trained model\n",
    "# model.save('osu_beatmap_lstm_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
