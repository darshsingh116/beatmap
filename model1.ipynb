{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data for MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Melokai.dataReadFromDisk import *\n",
    "df = load_df_from_csv()\n",
    "# df = df[df[\"total_length\"]<120]\n",
    "df = df[(df[\"BeatDivisor\"]==4) & (df[\"total_length\"]<300)]\n",
    "# df=df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_batch,input_audios,output_beatmaps,processed_beatmap_list,hyper_params_list = new_process_audio_and_beatmap_for_model_all_and_save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of (first_column, second_column) pair to specific index in 21-feature space\n",
    "combination_map = {\n",
    "    (0, 0): 0,\n",
    "\n",
    "    (1, 0): 1, \n",
    "    (5, 0): 1, \n",
    "\n",
    "    (2, 0): 2, (2, 1): 3, (2, 2): 4,\n",
    "    (6, 0): 2, (6, 1): 3, (6, 2): 4,\n",
    "\n",
    "    (8, 0): 5, (8, 1): 6, (8,2):7,\n",
    "    (12, 0): 5, (12, 1): 6, (12,2):7,\n",
    "\n",
    "}\n",
    "\n",
    "# Output list of 21-features\n",
    "output_8_features = []\n",
    "\n",
    "for op in output_beatmaps:\n",
    "    temp = []\n",
    "    \n",
    "    # For each row in the op, create a 21-element array with zeros\n",
    "    for row in op:\n",
    "        feature_row = np.zeros(8, dtype=int)\n",
    "        \n",
    "        # Get the values of the first and second columns\n",
    "        first_col, second_col = row[0], row[1]\n",
    "        \n",
    "        # Check if this (first_col, second_col) pair exists in the combination_map\n",
    "        if (first_col, second_col) in combination_map:\n",
    "            # Set the corresponding position to 1\n",
    "            index = combination_map[(first_col, second_col)]\n",
    "            feature_row[index] = 1\n",
    "        \n",
    "        # Append the feature row to temp\n",
    "        temp.append(feature_row)\n",
    "    \n",
    "    # Convert temp to a numpy array and append to output_21_features\n",
    "    output_8_features.append(np.array(temp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audios_with_hyperparams = []\n",
    "#scale hyper params \n",
    "#divide by [350,300,1,10,10,10,10,10,10,10,10,10]\n",
    "\n",
    "for index, ia in enumerate(input_audios):\n",
    "    temp = []\n",
    "    normalizedHyperParams = [(hyper_params_list[index][0]/350),(hyper_params_list[index][1]/300),(hyper_params_list[index][2]/350),(hyper_params_list[index][3]/10),(hyper_params_list[index][4]/10),(hyper_params_list[index][5]/10),(hyper_params_list[index][6]/10),(hyper_params_list[index][7]/10),(hyper_params_list[index][8]/10),(hyper_params_list[index][9]/10),(hyper_params_list[index][10]/10)]\n",
    "    for row in ia:\n",
    "        new_row = np.concatenate((row, normalizedHyperParams))\n",
    "        temp.append(new_row)\n",
    "\n",
    "    input_audios_with_hyperparams.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TO TRAIN\n",
    "on python 3.12.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example variables\n",
    "input_list = input_audios_with_hyperparams  # This is your list of song inputs, where each song is (num_beats, 13)\n",
    "output_list = output_8_features  # This is your list of song outputs, where each song is (num_beats, 2)\n",
    "\n",
    "# Parameters\n",
    "num_input_features = 91  # 91 features per beat in input\n",
    "num_output_features = 8  # 8 features to predict per beat\n",
    "\n",
    "# Padding sequences (songs) to handle variable length songs\n",
    "padded_inputs = pad_sequences(input_list, padding='post', dtype='float32')\n",
    "padded_outputs = pad_sequences(output_list, padding='post', dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define Transformer block (same as before)\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Position Embedding Layer\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "        self.token_emb = layers.Embedding(input_dim=10000, output_dim=embed_dim)  # adjust input_dim based on vocabulary size\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-2]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "# Custom model with masking and Transformer block\n",
    "# In ModelWithMasking class\n",
    "class ModelWithMasking(tf.keras.Model):\n",
    "    def __init__(self, maxlen, embed_dim, num_heads, ff_dim, num_classes):\n",
    "        super(ModelWithMasking, self).__init__()\n",
    "        self.position_embedding = PositionEmbedding(maxlen, embed_dim)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.output_layer = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Masking for padded inputs\n",
    "        mask = tf.cast(tf.not_equal(tf.reduce_sum(inputs, axis=-1), 0), dtype=tf.float32)[:, :, tf.newaxis]\n",
    "        \n",
    "        x = self.position_embedding(inputs)\n",
    "        x = self.transformer_block(x, mask=mask)\n",
    "        # Remove the pooling layer to get sequence outputs\n",
    "        return self.output_layer(x)  # This will output shape (batch_size, seq_len, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# Example setup\n",
    "maxlen_input = padded_inputs.shape[1]  # Length of padded input sequences\n",
    "embed_dim = 91  # Embedding dimension (should match your input features)\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 128  # Size of feedforward network in transformer\n",
    "num_classes = 8  # Number of output classes (hitobject types)\n",
    "\n",
    "# Building the model\n",
    "model = ModelWithMasking(maxlen_input, embed_dim, num_heads, ff_dim, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Example training\n",
    "history = model.fit(padded_inputs, padded_outputs, epochs=10, batch_size=8)\n",
    "\n",
    "# Generating prediction for the padded input at index 4\n",
    "# output_for_input_4 = model.predict(padded_inputs[4:5])  # Predict for a batch of size 1\n",
    "# print(output_for_input_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_output = model.predict(padded_inputs[2:3])  # Predict for a batch of size 1\n",
    "# predicted_output will be of shape (1, time_steps, num_output_features), we remove the batch dimension to print it\n",
    "predicted_output = np.squeeze(predicted_output, axis=0)  # Shape: (time_steps, num_output_features)\n",
    "\n",
    "predicted_classes = np.argmax(predicted_output, axis=-1)\n",
    "\n",
    "# Convert to one-hot encoding (hardmax transformation)\n",
    "one_hot_predictions = np.zeros_like(predicted_output)\n",
    "\n",
    "# Set the max probability class index to 1, others remain 0\n",
    "for i, class_idx in enumerate(predicted_classes):\n",
    "    one_hot_predictions[i, class_idx] = 1\n",
    "\n",
    "\n",
    "for p in one_hot_predictions:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(padded_inputs, padded_outputs, epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model is trained and padded_inputs[0] is your test input\n",
    "# padded_inputs[0]: shape (time_steps, num_input_features)\n",
    "test_input = np.expand_dims(padded_inputs[20], axis=0)  # Add batch dimension, shape becomes (1, time_steps, 24)\n",
    "\n",
    "# Get the model prediction\n",
    "predicted_output = model.predict(test_input)\n",
    "\n",
    "# predicted_output will be of shape (1, time_steps, num_output_features), we remove the batch dimension to print it\n",
    "predicted_output = np.squeeze(predicted_output, axis=0)  # Shape: (time_steps, num_output_features)\n",
    "\n",
    "predicted_classes = np.argmax(predicted_output, axis=-1)\n",
    "\n",
    "# Convert to one-hot encoding (hardmax transformation)\n",
    "one_hot_predictions = np.zeros_like(predicted_output)\n",
    "\n",
    "# Set the max probability class index to 1, others remain 0\n",
    "for i, class_idx in enumerate(predicted_classes):\n",
    "    one_hot_predictions[i, class_idx] = 1\n",
    "\n",
    "\n",
    "for p in one_hot_predictions:\n",
    "    print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
